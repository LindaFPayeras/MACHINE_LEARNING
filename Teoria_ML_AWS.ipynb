{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Foundations\n",
    "*Linda Fei Payeras Olano | Según AWS*\n",
    "\n",
    "![Imagen IA](./Mult_Teoria_ML_AWS/image1.jpeg) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido\n",
    "\n",
    "1. [Módulo 2](Teoria_ML_AWS.ipynb#módulo-2)\n",
    "    - [¿Qué es ML?](#qué-es-machine-learning)\n",
    "    - [Problemas empresariales resueltos con ML](#problemas-empresariales-resueltos-con-machine-learning)\n",
    "    - [Proceso del ML](#proceso-de-ml)\n",
    "    - [Desafios del ML](#desafios-del-ml)\n",
    "2. [Módulo 3: Implementacion de una canalizacion de aprendizaje automático](#módulo-3)\n",
    "3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Módulo 2\n",
    "### ¿Qué es Machine Learning?\n",
    "\n",
    "Es un subconjunto de la Inteligencia Artificial (IA) que es una amplia rama de las ciencias de la computación para crear máquinas que se puedan realizar tareas humanas. El Deap Learning (DL) es un subdominio del ML. \n",
    "\n",
    "![Estructura de IA, ML, DL, IA generativa](./Mult_Teoria_ML_AWS/image2.png)\n",
    "\n",
    "- <u>AGI (Artificial General Inteligence)</u>: Pueden aprender o comprender cualquier tarea que pueda entender un ser humano.\n",
    "- <u>Machine learning</u>: Es el estudio científico de algoritmos y modelos estadísticos para realizar una tarea utilizando inferencia en lugar de instrucciones. \n",
    "![Flujo ML](./Mult_Teoria_ML_AWS/image3.png)\n",
    "\n",
    "Deep learning o aprendizaje profundo representa un avance significativo en las capacidades de la IA y ML. La teoría se basó en cómo funciona el cerebro humano → redes neuronales artificiales (ANN, Artificial Neuronal Network) se inspira en las neuronas biológicas del cerebro.\n",
    "\n",
    "<u>Redes neuronales artificiales:</u>\n",
    "-\t+1 entradas y 1 única salida\n",
    "-\tDesencadenan la activación de sus salidas en función de la transformación de entradas.\n",
    "-\tSe compone de capas de neuronas con conexiones entre las capas.\n",
    "    + Capas de entrada: Datos de entrenamiento\n",
    "    + Capa de salida: respuesta a los problemas que se planteen\n",
    "    + Capas ocultas\n",
    "-\tFuncionamiento:\n",
    "        Se le mete un problema y las neuronas se activan. Las capas de entrada contienen los datos de entrenamiento y van procesando la información en las capas ocultas hasta que en la capa de salida se devuelve un resultado. Se procede a comprobar el resultado exacto y lo que debería de haber dado. Si no es correcto se repite el proceso con diferentes pesos en las neuronas hasta que se consigue. En cada iteración se fortalece las conexiones que conducen al éxito y debilitan las que llevan al fracaso. \n",
    "\n",
    "\n",
    "**LA IA GENERATIVA**\n",
    "\n",
    "Es un tipo de IA que puede crear nuevos contenidos e ideas, como conversaciones, historias, imágenes, videos y música. La IA generativa se basa en modelos de ML de gran tamaño entrenados previamente con grandes cantidades de datos.\n",
    "- <u>Modelos Fundacionales (FM)</u>: puede utilizarse para distintas tareas sin necesidad de entrenamiento adicional. Se usa para mejorar la experiencia del cliente a través de chatbots, asistentes virtuales, centros de contacto inteligentes, personalización y moderación de contenido.\n",
    "\n",
    "\n",
    "**AVANCES TECNOLOGICOS Y ML**\n",
    "\n",
    "A mediados de la década de los 2000 comenzaron a producir avances rápidos gracias a la **ley de Moore** y auge de la <u>computación en la nube</u>.\n",
    "-\tComputación en la nube: fácil acceso a las capacidades de computo y almacenamiento mayores, más rápidas y baratas. \n",
    "    + Ahora se puede alquilar rendimiento informático h/$ en comparación con las inversiones a gran escala de antes\n",
    "\n",
    "2012 el uso de redes neuronales comenzó en el Desafío de reconocimiento visual a gran escala de ImageNet → índice subió al 82% y en 2015 superó el rendimiento humano.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    ### Problemas empresariales resueltos con Machine Learning\n",
    "\n",
    "**TIPOS DE MACHINE LEARNING**\n",
    "![Diagrama](./Mult_Teoria_ML_AWS/image4.png)\n",
    "\n",
    "-\tAprendizaje supervisado: Un modelo usa entradas y salidas conocidas para generalizar resultados futuros. Es ampliamente aplicable. Se necesita:\n",
    "    + Un supervisor/ profesor que muestre las respuestas correctas al modelo\n",
    "\n",
    "    Aprende con ejemplos los cuales son datos etiquetados para identificar con exactitud en otros contextos lo que busca. Aunque tiene problemas\n",
    "\t\n",
    "    + <u>Clasificación binaria</u>: La variable objetivo de este ejemplo está limitada a dos opciones, aunque también existen los problemas de clasificación multiclase \n",
    "    + <u>Regresión</u>: No mapea una entrada a un número definido de categorías. Mapea a un valor continuo como un numero entero. Por ejemplo, al querer predecir el precio de las acciones de una empresa, estas podrían subir de 113 a 127$ por acción. \n",
    "\n",
    "![Clasificación](./Mult_Teoria_ML_AWS/image5.png)\n",
    "\n",
    "La **visión artificial** (CV) es un amplio campo que consiste en problemas de clasificación. Permite a las maquinas identificar personas, lugares y objetos en imágenes con una exactitud equivalente o superior a los niveles humanos con mayor velocidad y eficiencia. A menudo se crea con modelos DL\n",
    "\n",
    "-   <u>**Aprendizaje no supervisado**</u>: El modelo no conoce\n",
    "    entradas ni salidas; detecta patrones en los datos sin ayuda.\n",
    "\n",
    "    + No se proporcionan etiquetas porque no conoce todas las variables y patrones.\n",
    "    + La máquina debe descubrir y crear las etiquetas por sí misma.\n",
    "    + Usan datos que se les presentan para detectar las propiedades emergentes de todo el conjunto de datos\n",
    "\n",
    "Un tipo de aprendizaje no supervisado se **agrupa en clústeres** diferentes que se basan en características similares para comprender mejor los atributos de un clúster. Así puede ver patrones en los datos.\n",
    "\n",
    "![](./Mult_Teoria_ML_AWS/image6.png)\n",
    "\n",
    "**PROCESAMIENTO DEL LENGUAJE NATURAL**\n",
    "\n",
    "Otra área del ML usado para chatbots o centros de llamadas, herramientas de traducción, transcripciones, análisis de sentimientos…\n",
    "\n",
    "-\t<U>**Aprendizaje por refuerzo**</U>: El modelo interactúa con su entorno y debe aprender a tomar acciones que maximicen las compensaciones. \n",
    "\n",
    "    Mejora continuamente el modelo recopilando información de iteraciones anteriores. Aprende a través de ensayos y errores. Se utiliza cuando se conoce la recompensa de un resultado previsto pero no el camino para conseguirlo.\n",
    "        \n",
    "    + Lo que impulsa el aprendizaje se llama agente\n",
    "    + El lugar donde el agente aprende es el entorno\n",
    "    + Cuando el agente hace algo provocando una respuesta del entorno se llama acción\n",
    "    + La respuesta tras la acción se le llama recompensa o penalización dependiendo de si debe ser reforzado o descartado en el modelo\n",
    "\n",
    "    A medida que el agente se mueve en el entorno, sus acciones deben seguir recibiendo más recompensas y menos penalizaciones.\n",
    "\n",
    "        Vehículos autónomos reúnen varios algoritmos y modelos de DL y ML para resolver el problema de conducir de A a B.\n",
    "\n",
    "    La mayoría de los problemas son de aprendizaje supervisado\n",
    "\n",
    "**¿CÓMO UTILIZAR MACHINE LEARNING?**\n",
    "\n",
    "No todos los problemas se deben resolver con ML, a veces la programación básica funciona igual de bien.  Cuando se baraje la opción de ML, hay que buscar aspectos como la existencia de grandes conjuntos de datos y una gran cantidad de variables.\n",
    "\n",
    "### Proceso de ML\n",
    "**CANALIZACIÓN DE ML**\n",
    "\n",
    "![](./Mult_Teoria_ML_AWS/image7.png)\n",
    "\n",
    "1.\t**Problema empresarial:** Articular el problema empresarial y convertirlo en un problema de ML\n",
    "2.\t**Preparación de datos:** Extracción de datos y la fase de procesamiento previo. Se usa visualización de datos y estadísticas par determinar si los datos son coherentes y se puedan usar para ML. \n",
    "3.\t**Entrenamiento de modelos iterativos:** El proceso se vuelve iterativo y fluido. Es probable que se enfrente a varios procesos de ingeniería de características, entrenamiento, evaluación y ajuste antes de encontrar un modelo que se ajuste a sus objetivos empresariales. \n",
    "    \n",
    "    -\t**Ingeniería de características:** Proceso de selección o creación de características que utilizará para entrenar el modelo. Intentamos estimar correctamente el calor objetivo para los nuevos datos, el algoritmo de ML usa las características para predecir el destino. Algunos cambios que pueden surgir es la limpieza de datos en columnas, convertir atributos en conjuntos numéricos o binarios de columnas, o dividir la fecha de nacimiento en las partes que la componen\n",
    "    \n",
    "    - **Entrenamiento de modelos:** Se suele usar alrededor de 80% de los datos para tener algunos con los que realizar pruebas. \n",
    "\n",
    "4.\t**Evaluación y ajuste del modelo:** Uso de datos de prueba para ver qué tan bien funciona el modelo: se pide una predicción al modelo y, como ya tenemos lo que debería salir, podemos comparar lo que debería de salir. Se mejorará y modificarán los daros para que el modelo proporcione buenos resultados.\n",
    "5.\t**Sobreajuste e infraajuste:**\n",
    "    - **Sobreajuste:** cuando funciona bien los datos de entrenamientos, pero no los datos de evaluación. El modelo memoriza los datos que ha visto y no puede generalizar a ejemplos no vistos.\n",
    "    - **Infraajuste:** cuando su rendimiento es deficiente en los datos de entrenamiento. El modelo no puede determinar la relación entre los ejemplos de entrada y los valores objetivo.\n",
    "6.\t**Implementación:** Satisfecho con los resultados, se implementa el modelo para ofrecer las mejores predicciones posibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desafios del ML\n",
    "\n",
    "El ML plantea muchos desafíos como:\n",
    "\n",
    "| **Categoría**    | **Descripción** |\n",
    "|-----------------|---------------------------------------------|\n",
    "| **EN DATOS**    | - Deficiente  <br> - No representativo  <br> - Insuficiente  <br> - Sobreajuste e infraajuste |\n",
    "| **USUARIOS**    | - Falta de experiencia en ciencia de datos  <br> - Costos de personal con C. Datos  <br> - Falta de soporte de administración |\n",
    "| **APLICACIÓN**  | - Complejidad en la formulación de preguntas  <br> - Cómo explicar los modelos a la empresa  <br> - Costo de los sistemas de desarrollo |\n",
    "| **TECNOLOGÍA**  | - Problemas de privacidad de datos  <br> - Complicado seleccionar herramientas  <br> - Integración con otros sistemas |\n",
    "\n",
    "Hay muchos problemas de ML que se pueden resolver actualmente con pocos conocimientos en ML usando los modelos ya existentes. Se usan modelos ya entrenados a los que se les puede agregar sofisticadas capacidades (YOLO). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Módulo 3\n",
    "Vamos a desarrollar la canalizacion de Machine Learning por cada sección:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduccion al escenario\n",
    "- **Definir el objetivo empresarial**\n",
    "    Comprender el objetivo empresarial porque usará ese objetivo para medir el rendimiento de la solución. \n",
    "    +  ¿Cómo se realiza esta tarea en la actualidad?\n",
    "    + ¿Cómo hará la empresa para medir el éxito?\n",
    "    + ¿Cómo se utilizará la solución?\n",
    "    + ¿Existen soluciones similares de las que aprender ?\n",
    "    + ¿Qué supuestos ha hecho?\n",
    "    + ¿Quiénes son los expertos en dominios?\n",
    "\n",
    "- **Cómo se deberia enmarcar este problema?**\n",
    "    Se puede diseñar un enfoque. 1º. ¿Puede el ML resolver el problema o un enfoque más tradicional tendría más sentido? Luego ver si es un problema de ML supervisado o sin supervisar. En última instancia se debe intentar validar el uso de ML y confirmar que tiene acceso a las personas y los datos adecuados y finalmente idearla solución para el problema\n",
    "\n",
    "- **Transformarlo en un modelo de ML**\n",
    "    \n",
    "    Ahora hay que empezar a verlo de manera M:\n",
    "    + Resultado: qué desea ver de manera específica. \n",
    "    + Uso de datos: con un historial de datos, por ejemplo, podemos dar paso a un aprendizaje supervisado\n",
    "\n",
    "### Recopilacion y protección de datos\n",
    "- **¿Qué datos necesita?**\n",
    "    Ver qué datos se necesitan para poder llegar a la solución correcta, cuántos se necesitan, dónde están y qué solución se puede ofrecer para incorporar todos estos datos en un repositorio centralizado\n",
    "\n",
    "#### Orígenes de datos\n",
    "- **Datos privados**: datos que los clientes crean\n",
    "- **Datos comerciales**: AWS Data Exchange, AWS Marketplace y otros proveedores externos\n",
    "-\t**Datos de codigo abierto**: datos que se encuentran disponibles públicamente (revisar límites de uso)\n",
    "-\t**Observaciones**: datos en los que la respuesta de destino o predicción ya se sabe. También son llamados datos etiquetados. Se componen de:\n",
    "    - **Objetivo**: la respuesta que quiere predecir\n",
    "    - **Funciones**: atributos o variables que describen cada observación.\n",
    "\n",
    "\n",
    "- **Extracción, transformación y carga ETL**\n",
    "![](./Mult_Teoria_ML_AWS/image8.png)\n",
    "    Los datos, generalmente están distribuidos en distintos sistemas y proveedores de datos. El desafío es juntar todos esos orígenes de datos en algo que un modelo de ML pueda consumir. Los pasos para un proceso de ETL son:\n",
    "\n",
    "    - Extraer: tomar datos de los orígenes y ubicarlos a una única ubicación.\n",
    "    -\tTransformar: durante la extracción es posible que haya que modificar los datos, combinar los registros de coincidencia o podrían requerirse realizar otras transformaciones. \n",
    "    -\tCargar: finalmente, los datos se cargan en un repositorio. \n",
    "\n",
    "    Un marco de trabajo típico de ETL tiene varios componentes:\n",
    "\n",
    "    -\tCrawler: un programa que se conecta a su almacén de datos. Avanza hacia una lista con prioridad de clasificaciones para determinar el esquema de los datos y crea tablas de metadatos en el catalogo de datos. \n",
    "    -\tTrabajo: la lógica empresarial se requiere para realizar un trabajo de ETL\n",
    "    -\tCronograma o evento: un servicio de planificación que ejecuta el proceso de ETL periódicamente\n",
    "\n",
    "    **Protección de los datos**\n",
    "    - **Politica de AWS identity and access management (AWS IAM)**: Es importante tener en consideracion la seguridad de los datos. En la siguiente imagen veremos las politicas para controlar el acceso de IAM:\n",
    "\n",
    "    ![](./Mult_Teoria_ML_AWS/image9.png)\n",
    "\n",
    "    - **Cifrado de datos**: Para que los datos estén seguros y cumplir con algunos requisitos legales\n",
    "    - **AWS cloud trail para auditorias**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de datos\n",
    "Antes de ejecutar estadísticas en los datos, se debe asegurar que estén en el formato correcto para ser analizados. Debe de tener algo de conocimiento del dominio para el problema que estamos intentando solucionar. \n",
    "\n",
    "Generalmente los datos se deben de poner en formato numérico para que los algoritmos de ML puedan usar los datos para realizar predicciones. Una de las librerías de Python de código abierto más populares es pandas. Puede reformatear datos de varios formatos como CSV, JSON, Excel, Pickle… Además, cuenta con el análisis de datos y las características de manipulación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(filtered)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m df_mobile:\n\u001b[1;32m---> 13\u001b[0m     df_mobile\u001b[38;5;241m.\u001b[39mapply(\u001b[43mextract_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[1;32mIn[47], line 10\u001b[0m, in \u001b[0;36mextract_numeric\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_numeric\u001b[39m(value):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Extract digits from the string and join them into a single string\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39misdigit, value))\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_mobile = pd.read_csv(\"Mobile_data.csv\", sep=',')\n",
    "\n",
    "# We are going to clean a bit this dataset\n",
    "\n",
    "# Function to extract numeric values\n",
    "def extract_numeric(value):\n",
    "    # Extract digits from the string and join them into a single string\n",
    "    filtered = ''.join(filter(str.isdigit, value))\n",
    "    return float(filtered)\n",
    "\n",
    "for value in df_mobile:\n",
    "    df_mobile.appl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 5.0, 8.0]\n"
     ]
    }
   ],
   "source": [
    "def extract_numeric(value : list ):\n",
    "    # Extract digits from the string and join them into a single string\n",
    "    filtered = ''.join(filter(str.isdigit, value))\n",
    "    return float(filtered)\n",
    "\n",
    "# Input list\n",
    "valores = [\"3mg\", \"5gb\", \"8t\"]\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "prueba = []\n",
    "\n",
    "# Iterate over the input list and apply the function\n",
    "for i in valores:\n",
    "    prueba.append(extract_numeric(i))\n",
    "\n",
    "# Print the result\n",
    "print(prueba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame\n",
    "Al cargar datos en pandas, estos se almacenan como un DataFrame. DATAFRAME: Estructura tabular general de tamaño variable, etiquetable en 2D con una columna potencialmente heterogénea. También se puede ver como si fuera una hoja de calculo o tabla SQL con instancias y atributos.\n",
    "\n",
    "Junto con los datos, se puede cargar un DF con un índice (etiquetas de filas) y columnas (etiquetas de columnas). Si se cargan los datos desde un CSV con una fila de encabezado, la columnas se crean desde el primer renglón del archivo. Si no tiene las etiquetas de los ejes, entonces las columnas se ordenarán según el orden de inserción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe 1:\n",
      "         0       1        2         3\n",
      "0     cat     dog  pidgeon  goldfish\n",
      "1       4       4        2         0\n",
      "2  mammal  mammal     bird      fish\n",
      "\n",
      "Dataframe 2:\n",
      "       cat     dog pidgeon goldfish\n",
      "0       4       4       2        0\n",
      "1  mammal  mammal    bird     fish\n"
     ]
    }
   ],
   "source": [
    "animal = ['cat','dog','pidgeon','goldfish']\n",
    "legs = [4,4,2,0]\n",
    "species = ['mammal','mammal','bird','fish']\n",
    "print(\"Dataframe 1:\\n\", pd.DataFrame([animal, legs, species]))\n",
    "print(\"\\nDataframe 2:\\n\", pd.DataFrame([legs, species], # Quitar la que vaya a ser el titulo de las columnas\n",
    "            columns= animal))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando realice el análisis de datos → se asegura que usa tipos de datos correctos. Se usa dtypes o info() para obtener información de los tipos de columnas. Se tiene que corregir si el tipo de dato es incorrecto.\n",
    "\n",
    "#### Estadisticas descriptivas\n",
    "Use las estadísticas descriptivas para comprender los datos mejor. Estas brindan info valiosa para poder procesar previamente de manera eficaz y prepararlos para el modelo de ML.\n",
    " \n",
    "-\tHistogramas\n",
    "-\tDiagramas de densidad\n",
    "-\tDiagramas de caja\n",
    " \n",
    "Para que pueda obtener una idea de lo que hay dentro de una característica en particular. \n",
    "\n",
    "##### Diagrama de caja (bigotes)\n",
    "\n",
    "![](./Mult_Teoria_ML_AWS/image11.jpeg)\n",
    "\n",
    "**DIAGRAMA DE CAJA:** Es un método para representar gráficamente grupos de datos numéricos a través de sus cuartiles. Los valores fuera de este alcance están representados por las líneas que se extienden desde la caja (*whiskers*) \n",
    "\n",
    "##### Trazado de estadisticas de variables multiples\n",
    "Cuando se tiene más de dos variables numéricas en un conjunto de datos de características, a veces es bueno observar la relación entre ellas. Un diagrama de dispersión es una buena manera de identificar relaciones especiales entre variables. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m algo \u001b[38;5;241m=\u001b[39m [\u001b[43mextract_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m df_mobile]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#df_mobile.head()\u001b[39;00m\n\u001b[0;32m      4\u001b[0m algo\n",
      "Cell \u001b[1;32mIn[47], line 10\u001b[0m, in \u001b[0;36mextract_numeric\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_numeric\u001b[39m(value):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Extract digits from the string and join them into a single string\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     filtered \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39misdigit, value))\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfiltered\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "algo = [extract_numeric(x) for x in df_mobile]\n",
    "\n",
    "#df_mobile.head()\n",
    "algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
